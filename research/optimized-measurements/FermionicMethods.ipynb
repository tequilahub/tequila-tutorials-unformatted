{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55095fc9",
   "metadata": {},
   "source": [
    "# Fermionic-algebra-based measurement optimization\n",
    "\n",
    "Fermionic-algebra-based measurement optimization techniques improve the efficiency of the quantum measurement of the molecular electronic Hamiltonian. This quantum measurement is one of the remaining challenges for the practicality of the variational quantum eigensolver \\[see [Phys. Rev. Research **4**, 033154 (2022)](https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.4.033154)\\]. Unlike the [qubit-algebra-based methods](./QubitMethods.ipynb), the fermionic-algebra-based methods introduced here uses the properties of the molecular electronic Hamiltonian (presented in the second quantized form):\n",
    "$$\n",
    "\\hat{H} = \\sum_{pq} h_{pq} \\hat{a}^{\\dagger}_{p} \\hat{a}_{q} + \\sum_{pqrs} g_{pqrs} \\hat{a}^{\\dagger}_{p} \\hat{a}_{q} \\hat{a}^{\\dagger}_{r} \\hat{a}_{s}.\n",
    "$$\n",
    "The main idea behind the measurement technique is that Hartree&ndash;Fock (HF) solvable parts can be transformed by orbital rotations into functions of occupation number operators $\\hat{n}_{p} = \\hat{a}^{\\dagger}_{p} \\hat{a}_{p}$. These $\\hat{n}_{p}$'s can be measured directly on a digital quantum computer because they transform to $\\hat{z}$ under the Jordan&ndash;Wigner transformation.\n",
    "More details of measurement techniques based on partitioning $\\hat{H}$ into HF solvable parts can be found in [PRX Quantum **2**, 040320 (2021)](https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.2.040320). \n",
    "\n",
    "The following two techniques are available within Tequila:\n",
    "\n",
    "1. Low-rank (LR) decomposition [npj Quantum Inf. **7**, 23 (2021)](https://www.nature.com/articles/s41534-020-00341-7)\n",
    "\n",
    "2. Fluid fermionic fragments (F$^{3}$) [Quantum **7**, 889 (2023)](https://quantum-journal.org/papers/q-2023-01-03-889/pdf/)\n",
    "\n",
    "One potential drawback of LR is the high number of measurements required to obtain the expectation value of $\\hat{H}$ as demonstrated in [PRX Quantum **2**, 040320 (2021)](https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.2.040320). \n",
    "F$^3$ exploits the properties of the HF solvable parts obtained by LR to significantly reduce this required number of measurements. The resulting F$^3$-LR technique has lower quantum measurement costs than even the best qubit-algebra-based techniques \\[see [Quantum **7**, 889 (2023)](https://quantum-journal.org/papers/q-2023-01-03-889/pdf/)\\].  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989cc434",
   "metadata": {},
   "source": [
    "## Common to both LR and F$^3$\n",
    "\n",
    "### Setting up the test Hamiltonian\n",
    "For concreteness, we demonstrate LR and F$^3$ using H$_4$ in the STO-3G basis.\n",
    "\n",
    "Many of Tequila's functions including the one for measuring the expectation value of $\\hat{H}$ takes Tequila's QubitHamiltonian as an input. However, the fermionic-algebra-based measurement optimization techniques require the fermionic Hamiltonian in the second quantized form. We use OpenFermion's reverse_jordan_wigner function to obtain the fermionic Hamiltonian back from Tequila's QubitHamiltonian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6868a70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged SCF energy = -2.09854593699776\n",
      "Number of Pauli products to measure: 184\n"
     ]
    }
   ],
   "source": [
    "# Needs pyscf or psi4 installed:\n",
    "# pip install pyscf\n",
    "# tequila version needs to be > 1.8.3 or from devel branch\n",
    "import tequila as tq\n",
    "from tequila.hamiltonian import QubitHamiltonian\n",
    "from tequila.grouping.fermionic_functions import n_elec\n",
    "from openfermion import reverse_jordan_wigner\n",
    "import numpy as np\n",
    "\n",
    "def prepare_test_hamiltonian():\n",
    "    '''\n",
    "    Return a test hamiltonian.\n",
    "    '''\n",
    "    trafo = \"JordanWigner\"\n",
    "    mol = tq.chemistry.Molecule(\n",
    "                            geometry=\"H 0.0 0.0 0.0 \\n H 0.0 0.0 1. \\n H 0.0 0.0 2. \\n H 0.0 0.0 3.\",\n",
    "                            basis_set=\"sto3g\",\n",
    "                            transformation=trafo,\n",
    "                            backend='pyscf'\n",
    "                                 )\n",
    "    H = mol.make_hamiltonian()\n",
    "    Hq = H.to_openfermion()\n",
    "    Hferm = reverse_jordan_wigner(Hq)\n",
    "    return mol, H, Hferm, len(Hq.terms) - 1\n",
    "\n",
    "mol, H, Hferm, n_paulis = prepare_test_hamiltonian()\n",
    "print(\"Number of Pauli products to measure: {}\".format(n_paulis))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a50eb0",
   "metadata": {},
   "source": [
    "## Low-rank decomposition\n",
    "\n",
    "### Running LR\n",
    "\n",
    "To obtain HF solvable fragments using the LR decomposition, one can simply execute the following.\n",
    "As outputs, we obtain the HF solvable parts as orbital rotations (orb_rot) and the cartan subalgebra polynomials: There is a single one-body term (cartan_obt) and multiple two-body terms (cartan_tbts). The suggested measurement allocation (meas_alloc) is the optimal sample (shot) allocation for each HF solvable fragment minimizing the number of required number of measurements. Optimal meas_alloc is computed using the configuration interaction singles and doubles (CISD) wavefunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb0bc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SVD routine\n",
      "Diagonalizing two-body tensor\n",
      "Truncating SVD for coefficients with magnitude smaller or equal to 8.898272270834066e-18, using 10 fragments\n",
      "Finished SVD routine\n",
      "Allocating measurements\n"
     ]
    }
   ],
   "source": [
    "from tequila.grouping.fermionic_methods import do_svd\n",
    "\n",
    "orb_rots, cartan_obt, cartan_tbts, meas_alloc = do_svd(Hferm, n_elec(\"h4\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e979bbbd",
   "metadata": {},
   "source": [
    "### Number of required measurements in LR\n",
    "\n",
    "In the following, we estimate the number of measurements (in millions) required to obtain the Hamiltonian expectation value with a millihartree accuracy. For this estimation, we suppose that one is interested in measuring $\\langle \\mathrm{FCI} | \\hat{H} | \\mathrm{FCI} \\rangle$ because all succesful VQE algorithms should converge close to the FCI solution. To evaluate the measurement cost, we use Eq. (4) from [Quantum **7**, 889 (2023)](https://quantum-journal.org/papers/q-2023-01-03-889/pdf/). \n",
    "\n",
    "In the output, \"Full variances\" show the variance of each HF solvable fragments, and \"Expectations\" show their expectation values. The metric in Eq. (4) is shown by \"Variance metric value\" and \"Exp value\" is the expectation value of $\\hat{H}$, obtained by summing the fragments' expectation values:\n",
    "$$\n",
    "\\langle \\mathrm{FCI} | \\hat{H} | \\mathrm{FCI} \\rangle = \\sum_{\\alpha} \\langle \\mathrm{FCI} | \\hat{H}_{\\alpha} | \\mathrm{FCI} \\rangle,\n",
    "$$\n",
    "where $\\hat{H}_{\\alpha}$ are the HF solvable fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93bb43c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full variances:\n",
      "[1.25991914e-01 1.36077664e-01 1.42450177e-02 4.37352361e-02\n",
      " 2.11796719e-02 2.34092987e-04 5.93277530e-05 3.37726148e-05\n",
      " 1.48370444e-09 4.65833765e-10 2.16294055e-17]\n",
      "Expectations\n",
      "[-8.42898449e+00  3.60748346e+00  6.17420954e-02  1.48399801e-01\n",
      "  1.09695039e-01  1.62661519e-02  1.88238558e-03  2.39898990e-02\n",
      "  2.19853203e-05  1.48979274e-05  9.95470945e-09]\n",
      "Variance metric value is 1.5050679489201466\n",
      "Exp value is -2.1663875200311833\n"
     ]
    }
   ],
   "source": [
    "from tequila.grouping.fermionic_functions import obt_to_ferm, convert_tbts_to_frags\n",
    "from tequila.grouping.fermionic_methods import get_wavefunction, compute_and_print_ev_var\n",
    "\n",
    "def cartan_to_fermionic_operator(cobt, ctbts, orb_rot):\n",
    "    '''\n",
    "    Turn Cartan polynomials into OpenFermion's FermionOperator.\n",
    "    '''\n",
    "    obt = np.einsum(\"pa, qb, ab\", orb_rot[0], orb_rot[0], cobt)\n",
    "    tbts = np.einsum(\"ipa, iqb, irc, isd, iabcd -> ipqrs\", \n",
    "                     orb_rot[1:], orb_rot[1:], orb_rot[1:], orb_rot[1:], ctbts)\n",
    "    ferm_ops = [obt_to_ferm(obt,True)] + convert_tbts_to_frags(tbts, True)\n",
    "    return ferm_ops\n",
    "\n",
    "ferm_ops = cartan_to_fermionic_operator(cartan_obt, cartan_tbts, orb_rots)\n",
    "#Compute the number of required measurements [Eq.(4) from Quantum 7, 889 (2023)] using the FCI wavefunction.\n",
    "_, psis_fci = get_wavefunction(H.to_openfermion(), \"fci\", \"h4\", n_elec(\"h4\"), save=False)\n",
    "compute_and_print_ev_var(psis_fci[0], Hferm, ferm_ops, meas_alloc=meas_alloc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc4711",
   "metadata": {},
   "source": [
    "## Fluid fermionic fragments (with LR fragments)\n",
    "\n",
    "### Running F$^3$-LR and obtaining the number of required measurements\n",
    "\n",
    "Unlike the LR decomposition, which did not require any input options, one can specify several options for F$^3$. Here is a summary of possible options:\n",
    "\n",
    "1. mol_name (default null): Name of the molecule to perform FFF. Used for saving restart files.\n",
    "2. fff_method (default R2): Full/R1/R2 \\[see [Quantum **7**, 889 (2023)](https://quantum-journal.org/papers/q-2023-01-03-889/pdf/)\\]. Full takes more classical computational time than R1 and R2, but has lower number of quantum measurements.\n",
    "3. n_iter (default 5): Number of FFF iterations.\n",
    "4. trunc_perc (default 100): For improved efficiency, CISD wavefunction can be truncated to include only a few significant slater determinants. trunc_perc specifies what percentage of the CISD wavefunction one wishes to retain. \n",
    "5. fff_thresh (default 1e-4): One can choose to only apply F$^3$ technique on a few of the HF solvable fragments. F$^3$ is only applied to the fragments with variances above fff_thresh. The larger the fff_thresh, the faster the algorithm, but the larger the quantum measurement cost. \n",
    "\n",
    "The options are passed to the do_fff function by using a dictionary (unspecified values are set to default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca87cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "options={\"mol_name\":\"h4\", \"fff_method\":\"R2\", \"trunc_perc\":99}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db7d44",
   "metadata": {},
   "source": [
    "Unlike in LR, one can directly print the number of required measurements in F$^3$ by specifying metric_estim=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a857a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SVD routine\n",
      "Diagonalizing two-body tensor\n",
      "Truncating SVD for coefficients with magnitude smaller or equal to 8.898272270834066e-18, using 10 fragments\n",
      "Finished SVD routine\n",
      "Using 4 slater determinants: 0.9926785298742373% of the approximate WF\n",
      "===================================================\n",
      "FCI info before optimization.\n",
      "Full variances:\n",
      "[1.25991914e-01 1.36077664e-01 1.42450177e-02 4.37352361e-02\n",
      " 2.11796719e-02 2.34092987e-04 5.93277530e-05 3.37726148e-05\n",
      " 1.48368937e-09 4.65833765e-10 2.16294055e-17]\n",
      "Expectations\n",
      "[-8.42898449e+00  3.60748346e+00  6.17420954e-02  1.48399801e-01\n",
      "  1.09695039e-01  1.62661519e-02  1.88238558e-03  2.39898990e-02\n",
      "  2.19852802e-05  1.48979274e-05  5.85181579e-08]\n",
      "Variance metric value is 1.5048658096596963\n",
      "Exp value is -2.166387471507828\n",
      "===================================================\n",
      "===================================================\n",
      "Getting approximate variances\n",
      "Applying F3 to 6 fragments out of 11\n",
      "===================================================\n",
      "Computing necessary covariance estimates\n",
      "Progress: iteration #1 out of 5\n",
      "Progress: iteration #2 out of 5\n",
      "Progress: iteration #3 out of 5\n",
      "Progress: iteration #4 out of 5\n",
      "Progress: iteration #5 out of 5\n",
      "Allocating measurements\n",
      "===================================================\n",
      "FCI info after optimization.\n",
      "Full variances:\n",
      "[7.22161124e-02 1.79119376e-04 1.42450177e-02 3.35728496e-02\n",
      " 2.11796719e-02 1.24794674e-04 5.93277530e-05 3.37726148e-05\n",
      " 1.48368937e-09 4.65833765e-10 2.16294055e-17]\n",
      "Expectations\n",
      "[-1.17491542e+00 -3.59525939e+00  6.17420954e-02  1.05916617e-01\n",
      "  1.09695039e-01  7.42311403e-03  1.88238558e-03  2.39898990e-02\n",
      "  2.19852802e-05  1.48979274e-05  5.85181579e-08]\n",
      "Variance metric value is 0.6003023301953059\n",
      "Exp value is -2.1663874715078326\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "from tequila.grouping.fermionic_methods import do_fff\n",
    "_ = do_fff(Hferm, n_elec(\"h4\"), options=options, metric_estim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0627a1",
   "metadata": {},
   "source": [
    "We can see that the number of measurements required to obtain the Hamiltonian expectation value has reduced by more than a factor of 2 from 1.5 million to 0.6 million by using the F$^3$ technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f261f58",
   "metadata": {},
   "source": [
    "## Measuring the expectation value using a quantum circuit\n",
    "\n",
    "Now let us use Tequila to measure the expectation value of a test wavefunction (wfn) on a quantum circuit. While the demonstration is only for F$^3$-LR, the LR decomposition can be used on its own by passing options_lr instead of options_f3_lr into tq.ExpectationValue. \n",
    "\n",
    "**Note that by default, reverse_jordan_wigner is used to obtain the fermionic Hamiltonian from Tequila's QubitHamiltonian to use a user-defined function instead, add {\"revserse_H_transf\":name_of_user_defined_func} to options_f3_lr.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71912221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using {'method': 'fff-lr', 'mol_name': 'h4', 'fff_method': 'R2', 'trunc_perc': 99} as options\n",
      "Using default reverse_H_transf, i.e., reverse_jordan_wigner.\n",
      "Using saved Hamiltonian from SAVE/h4/. Run with a different mol_name if this is not desired.\n",
      "Using saved LR decomposition saved in SAVE/h4/. Run with a different mol_name if this is not desired.\n",
      "Using saved psi_cisd in SAVE/h4/. Run with a different mol_name if this is not desired.\n",
      "Using 4 slater determinants: 0.9926785298742373% of the approximate WF\n",
      "===================================================\n",
      "Getting approximate variances\n",
      "Applying F3 to 6 fragments out of 11\n",
      "===================================================\n",
      "Computing necessary covariance estimates\n",
      "Progress: iteration #1 out of 5\n",
      "Progress: iteration #2 out of 5\n",
      "Progress: iteration #3 out of 5\n",
      "Progress: iteration #4 out of 5\n",
      "Progress: iteration #5 out of 5\n",
      "Allocating measurements\n",
      "Benchmark Energy: -3.636819839477539\n",
      "Energy measured with FÂ³-LR -3.6391637325286865\n"
     ]
    }
   ],
   "source": [
    "options_lr = {\"method\":\"lr\", \"mol_name\":\"h4\"}\n",
    "options_f3_lr = {\"method\":\"fff-lr\"}\n",
    "options_f3_lr.update(options)\n",
    "print(\"Using {} as options\".format(options_f3_lr))\n",
    "\n",
    "#Prepare test wavefunction (wfn)\n",
    "U = mol.make_ansatz(name=\"SPA\", edges=[(0,1), (2,3)])\n",
    "E = tq.ExpectationValue(H=H, U=U)\n",
    "result = tq.minimize(E, silent=True)\n",
    "wfn = tq.simulate(U, variables=result.variables)\n",
    "\n",
    "e_f3 = tq.ExpectationValue(H=H, U=U, optimize_measurements=options_f3_lr)\n",
    "\n",
    "#Print Benchmark Energy (unnecessary in real measurement).\n",
    "result_f3 = tq.simulate(e_f3, result.variables)\n",
    "print(\"Benchmark Energy:\", result_f3)\n",
    "\n",
    "compiled_f3 = tq.compile(e_f3)\n",
    "# auto-100000 means automatically allocate 100000 samples (shots) \n",
    "# between measurable fragments.\n",
    "exp_f3 = compiled_f3(result.variables, samples=\"auto-600000\")\n",
    "\n",
    "print(\"Energy measured with {}\\u00b3-LR\".format(\"F\"), exp_f3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
